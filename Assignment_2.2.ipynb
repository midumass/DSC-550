{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2.2 - Build Your Text Classifiers\n",
    "Zach Hill\n",
    "DSC-550-T302\n",
    "08DEC2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "tvect = TfidfVectorizer()\n",
    "dvect = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('./Income.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of kids</th>\n",
       "      <th>Income</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>122500</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>142007</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>42007</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14704</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>200704</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>120070</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>207040</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>48000</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>79000</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # of kids  Income State\n",
       "0          5   25000    CA\n",
       "1          5  122500    NY\n",
       "2          2  142007    TX\n",
       "3          2   42007    TX\n",
       "4          0   14704    TX\n",
       "5          1  200704    TX\n",
       "6          1  120070    CA\n",
       "7          3  207040    NY\n",
       "8          3   48000    NY\n",
       "9          3   79000    NY"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# of kids', 'Income', 'State'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    # Set headers to lower\n",
    "    col_clean = col.lower()\n",
    "    # Remove Punctuation from headers\n",
    "    col_clean = col_clean.translate(col_clean.maketrans('', '', string.punctuation)).lstrip(' ')\n",
    "    # Remove stop words from headers\n",
    "    if (col_clean.find(' ')!=-1):\n",
    "        word_tokens = word_tokenize(col_clean)\n",
    "        col_new = [word for word in word_tokens if word not in stop_words]\n",
    "        col_clean = ''.join([str(word) for word in col_new])\n",
    "        df.rename(columns = {col:col_clean}, inplace = True)\n",
    "    else:\n",
    "        if col_clean in stop_words:\n",
    "            col_clean = [word for word in word_tokens if word not in stop_words]\n",
    "            df.rename(columns = {col:col_clean}, inplace = True)\n",
    "        else:\n",
    "            df.rename(columns = {col:col_clean}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kids', 'income', 'state'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df.rename(columns = {col:ps.stem(col)}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kid', 'incom', 'state'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    5\n",
      "2    2\n",
      "3    2\n",
      "4    0\n",
      "5    1\n",
      "6    1\n",
      "7    3\n",
      "8    3\n",
      "9    3\n",
      "Name: kid, dtype: int64\n",
      "0     25000\n",
      "1    122500\n",
      "2    142007\n",
      "3     42007\n",
      "4     14704\n",
      "5    200704\n",
      "6    120070\n",
      "7    207040\n",
      "8     48000\n",
      "9     79000\n",
      "Name: incom, dtype: int64\n",
      "0    ca\n",
      "1    ny\n",
      "2    tx\n",
      "3    tx\n",
      "4    tx\n",
      "5    tx\n",
      "6    ca\n",
      "7    ny\n",
      "8    ny\n",
      "9    ny\n",
      "Name: state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    df[col] = df[col].apply(lambda x: x.lower() if(isinstance(x, str)) else x)\n",
    "    print(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvect.fit_transform(df['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca', 'ny', 'tx']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "             {\"Red\": 4, \"Blue\": 3},\n",
    "             {\"Red\": 1, \"Yellow\": 2},\n",
    "             {\"Red\": 2, \"Yellow\": 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dvect.fit_transform(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1_word_count = {\"Red\": 2, \"Blue\": 4}\n",
    "doc_2_word_count = {\"Red\": 4, \"Blue\": 3}\n",
    "doc_3_word_count = {\"Red\": 1, \"Yellow\": 2}\n",
    "doc_4_word_count = {\"Red\": 2, \"Yellow\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_counts = [doc_1_word_count,\n",
    "doc_2_word_count,\n",
    "doc_3_word_count,\n",
    "doc_4_word_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvect.fit_transform(doc_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "p = pd.read_table('./positive.txt', header = None, encoding = 'latin-1')\n",
    "n = pd.read_table('./negative.txt', header = None, encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will build tokenized lists for sentiment analysis using words from around 10000 reviews. To avoid imbalanced samples, each has the same number of reviews. These tokenized lists can be applied in text analysis to predict how other reviews would be considered (positive or negative).\n",
    "\n",
    "Source: https://pythonprogramming.net/new-data-set-training-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize positive reviews and remove punctuation\n",
    "p_tokens = p[0].apply(RegexpTokenizer('\\w+').tokenize)\n",
    "p_clean = []\n",
    "\n",
    "# Remove stop words from tokenized list and create new, clean list\n",
    "for val in p_tokens:\n",
    "    p_clean += [word for word in val if word not in stop_words]\n",
    "    \n",
    "# Build positive comment features and names vectors\n",
    "p_feat = tvect.fit_transform(p_clean)\n",
    "p_feat_names = tvect.get_feature_names()\n",
    "\n",
    "\n",
    "# Tokenize negative reviews and remove punctuation\n",
    "n_tokens = n[0].apply(RegexpTokenizer('\\w+').tokenize)\n",
    "n_clean = []\n",
    "\n",
    "# Remove stop words from tokenized list and create new, clean list\n",
    "for val in n_tokens:\n",
    "    n_clean += [word for word in val if word not in stop_words]\n",
    "    \n",
    "# Build negative comment features and names vectors\n",
    "n_feat = tvect.fit_transform(n_clean)\n",
    "n_feat_names = tvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<57821x12417 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 57652 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<56729x12758 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56543 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
